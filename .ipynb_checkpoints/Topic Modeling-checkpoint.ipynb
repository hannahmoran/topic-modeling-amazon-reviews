{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import logging\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import lda_funcs # helper functions for LDA tuning\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "handler = logging.FileHandler('training_output.log')\n",
    "\n",
    "# The handler above is somthing I needed with respect to logging.\n",
    "# Gensim performs various calculations while training the LDA model that I am using, but the only way to see them\n",
    "# is in the logging outputs.\n",
    "# Specifically, I need to capture the perplexity values during training to verify that perplexity is decreasing.\n",
    "# This metric is needed to compare models and to do hyperparameter tuning. \n",
    "\n",
    "\n",
    "# The following blog post was helpful to me in figure out how to make the log handler I needed.\n",
    "# https://fangpenlin.com/posts/2012/08/26/good-logging-practice-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_stripped</th>\n",
       "      <th>clean_vanilla_x</th>\n",
       "      <th>clean_coded_x</th>\n",
       "      <th>clean_valence_x</th>\n",
       "      <th>Vanilla Subtopic</th>\n",
       "      <th>Vanilla Subtopic Fit</th>\n",
       "      <th>Coded Subtopic</th>\n",
       "      <th>Coded Subtopic Fit</th>\n",
       "      <th>Valence Subtopic</th>\n",
       "      <th>Valence Subtopic Fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B000KV61FC</td>\n",
       "      <td>A1Y1YYH71TPYC6</td>\n",
       "      <td>thefinfan54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1222905600</td>\n",
       "      <td>The best dog toy I ever bought :)</td>\n",
       "      <td>...</td>\n",
       "      <td>two small dog absolutely love VGOODREVIEW tug ...</td>\n",
       "      <td>two small dog absolutely love tug jug many us ...</td>\n",
       "      <td>two small dog absolutely love GOODREVIEW tug j...</td>\n",
       "      <td>two small dog absolutely love VGOODREVIEW tug ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.395601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B000KV61FC</td>\n",
       "      <td>A1SLLKDKCZ5IPL</td>\n",
       "      <td>C. Guariglia</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1221091200</td>\n",
       "      <td>Buried Treasure Forever!</td>\n",
       "      <td>...</td>\n",
       "      <td>idea basically good GOODREVIEW one however lar...</td>\n",
       "      <td>idea basically good one however large papillon...</td>\n",
       "      <td>idea basically good GOODREVIEW one however lar...</td>\n",
       "      <td>idea basically good GOODREVIEW one however lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0.1.1   ProductId          UserId   ProfileName  \\\n",
       "0             0               0  B000KV61FC  A1Y1YYH71TPYC6   thefinfan54   \n",
       "1             1               1  B000KV61FC  A1SLLKDKCZ5IPL  C. Guariglia   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     2                       2      5  1222905600   \n",
       "1                     2                       2      2  1221091200   \n",
       "\n",
       "                             Summary         ...           \\\n",
       "0  The best dog toy I ever bought :)         ...            \n",
       "1           Buried Treasure Forever!         ...            \n",
       "\n",
       "                                    valence_stripped  \\\n",
       "0  two small dog absolutely love VGOODREVIEW tug ...   \n",
       "1  idea basically good GOODREVIEW one however lar...   \n",
       "\n",
       "                                     clean_vanilla_x  \\\n",
       "0  two small dog absolutely love tug jug many us ...   \n",
       "1  idea basically good one however large papillon...   \n",
       "\n",
       "                                       clean_coded_x  \\\n",
       "0  two small dog absolutely love GOODREVIEW tug j...   \n",
       "1  idea basically good GOODREVIEW one however lar...   \n",
       "\n",
       "                                     clean_valence_x Vanilla Subtopic  \\\n",
       "0  two small dog absolutely love VGOODREVIEW tug ...              1.0   \n",
       "1  idea basically good GOODREVIEW one however lar...              NaN   \n",
       "\n",
       "  Vanilla Subtopic Fit Coded Subtopic Coded Subtopic Fit Valence Subtopic  \\\n",
       "0             0.395601            1.0           0.271064              1.0   \n",
       "1                  NaN            NaN                NaN              NaN   \n",
       "\n",
       "  Valence Subtopic Fit  \n",
       "0             0.262538  \n",
       "1                  NaN  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews_subset.csv', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B002IEZJMA    487\n",
       "B006MONQMC    491\n",
       "B005ZBZLT4    506\n",
       "B003GTR8IO    530\n",
       "B005K4Q34S    541\n",
       "B0013A0QXC    542\n",
       "B000NMJWZO    542\n",
       "B000KV61FC    556\n",
       "B001EO5Q64    567\n",
       "B0026RQTGE    630\n",
       "Name: ProductId, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get review counts for each product\n",
    "review_counts = df['ProductId'].value_counts().sort_values()\n",
    "review_counts.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a couple product groups to work with - the 10 products with the largest number of reviews\n",
    "top_ten = review_counts.tail(10).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model Grid Search & Tuning\n",
    "\n",
    "For each of the input text types (vanilla, coded, and valence coded), first run an initial grid search with 50 or 80 training passes and either 6, 10, or 12 topics.\n",
    "\n",
    "NOTE: grid search can take hours to run fully - don't run the below cells unless you actually want to perform the searching and tuning. The csv results files can simply be loaded in where noted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "# load in the final results\n",
    "vanilla_final_results = pd.read_csv('vanilla_final_results.csv')\n",
    "vanilla_final_results.set_index('product', inplace=True)\n",
    "\n",
    "coded_final_results = pd.read_csv('coded_final_results.csv')\n",
    "coded_final_results.set_index('product', inplace=True)\n",
    "\n",
    "valence_final_results = pd.read_csv('valence_final_results.csv')\n",
    "valence_final_results.set_index('product', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Inputs Grid Search & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION - GRID SEARCH CAN TAKE MANY HOURS TO RUN\n",
    "# ONLY RUN ON FIRST PASS\n",
    "# create a dataframe to house the results of the model tuning from an initial grid search\n",
    "\n",
    "vanilla_gs_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                           'passes', 'per-word bounds', \n",
    "                                           'perplexity', 'topic diff', \n",
    "                                           'final perplexity', 'final topic diff', \n",
    "                                           'perplexity decreasing', 'coherence', \n",
    "                                           'top_n removed', 'n_above threshold'])\n",
    "\n",
    "# for each of the top ten products, grid search over a combination of n_passes and n_topics \n",
    "# save the parameter combinations (and saved model) of the model with the highest coherence score\n",
    "for product in top_ten:\n",
    "    output = lda_funcs.tune_lda(df=df, product=product, n_passes=[50, 80], \n",
    "                                n_topics=[6, 8, 10, 12], save_path='vanilla_outputs',\n",
    "                                input_text='clean_vanilla', n_below=0, \n",
    "                                top_n=[2,10], n_above=[0.5, 1.0])\n",
    "    vanilla_gs_results = lda_funcs.save_best(output, vanilla_gs_results, \n",
    "                                             save_path='vanilla_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ON FIRST PASS\n",
    "# save off the results with the best model (highest coherence) for each product\n",
    "# examine the results\n",
    "vanilla_gs_results.to_csv('vanilla_gs_results.csv')\n",
    "vanilla_gs_results[['product','coherence', 'num_topics', \n",
    "                    'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "vanilla_gs_results = pd.read_csv('vanilla_gs_results.csv')\n",
    "vanilla_gs_results[['product','coherence', 'num_topics', \n",
    "                    'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after reviewing the results of the initial grid search pass, and manually tune the models for each of the products to try to reach a threshold of 0.5 for the final model coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell for the products that needs further tuning\n",
    "# increase or decrease the number of passes or topics depending on the best model found from previous results\n",
    "output = lda_funcs.tune_lda(df=df, product='B0026RQTGE', n_passes=[80], \n",
    "                            n_topics=[5, 6, 7], save_path='vanilla_outputs',\n",
    "                            input_text='clean_vanilla', n_below=0, top_n=[2], \n",
    "                            n_above=[1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the outputs\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the result is an improvement, run this cell to save it\n",
    "# save off the updated results dataframe\n",
    "vanilla_gs_results = lda_funcs.save_best(output, vanilla_gs_results, \n",
    "                                         save_path='vanilla_outputs')\n",
    "vanilla_gs_results.to_csv('vanilla_gs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, save off the best results into a final output dataframe\n",
    "# create a df to collect the best models from all grid search tuning efforts\n",
    "# save it off to a csv\n",
    "vanilla_final_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                              'passes', 'per-word bounds', 'perplexity', \n",
    "                                              'topic diff', 'final perplexity', \n",
    "                                              'final topic diff', 'perplexity decreasing', \n",
    "                                              'coherence', 'top_n removed', 'n_above threshold'])\n",
    "\n",
    "for product in top_ten:\n",
    "    output = vanilla_gs_results[vanilla_gs_results['product']==product]\n",
    "    vanilla_final_results = lda_funcs.save_best(output, vanilla_final_results, \n",
    "                                                save_path='vanilla_outputs')\n",
    "\n",
    "vanilla_final_results.to_csv('vanilla_final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "# load in the final results\n",
    "vanilla_final_results = pd.read_csv('vanilla_final_results.csv')\n",
    "vanilla_final_results.set_index('product', inplace=True)\n",
    "vanilla_final_results[['coherence', 'num_topics', 'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that success with the vanilla review (i.e., no codewords, just clean text) was pretty poor - I was not able to achieve the 0.5 goal threshold with any of the products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coded Inputs Grid Search & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION - GRID SEARCH CAN TAKE MANY HOURS TO RUN\n",
    "# ONLY RUN ON FIRST PASS\n",
    "# create a dataframe to house the results of the model tuning from an initial grid search\n",
    "\n",
    "coded_gs_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                         'passes', 'per-word bounds', 'perplexity', \n",
    "                                         'topic diff', 'final perplexity', \n",
    "                                         'final topic diff', 'perplexity decreasing',\n",
    "                                         'coherence', 'top_n removed', 'n_above threshold'])\n",
    "\n",
    "# for each of the top ten products, grid search over a combination of n_passes and n_topics \n",
    "# save the parameter combinations (and saved model) of the model with the highest coherence score\n",
    "for product in top_ten:\n",
    "    output = lda_funcs.tune_lda(df=df, product=product, n_passes=[50, 80], \n",
    "                                n_topics=[6, 8, 10, 12], save_path='coded_outputs',\n",
    "                                input_text='clean_coded', n_below=0, \n",
    "                                top_n=[2,10], n_above=[0.5, 1.0])\n",
    "    coded_gs_results = lda_funcs.save_best(output, coded_gs_results, save_path='coded_outputs')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ON FIRST PASS\n",
    "# save off the results with the best model (highest coherence) for each product\n",
    "# examine the results\n",
    "coded_gs_results.to_csv('coded_gs_results.csv')\n",
    "coded_gs_results[['product','coherence', 'num_topics', \n",
    "                  'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "coded_gs_results = pd.read_csv('coded_gs_results.csv')\n",
    "coded_gs_results[['product','coherence', 'num_topics', \n",
    "                  'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after reviewing the results of the initial grid search pass, and manually tune the models for each of the products to try to reach a threshold of 0.5 for the final model coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell for the product that needs further tuning\n",
    "output = lda_funcs.tune_lda(df=df, product='B000KV61FC', n_passes=[50], \n",
    "                            n_topics=[9, 10, 11], save_path='coded_outputs',\n",
    "                            input_text='clean_coded', n_below=0, \n",
    "                            top_n=[2], n_above=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the outputs\n",
    "output[['product','coherence', 'num_topics', \n",
    "        'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the result is an improvement, run this cell to save it\n",
    "# save off the updated results dataframe\n",
    "coded_gs_results = lda_funcs.save_best(output, coded_gs_results, \n",
    "                                       save_path='coded_outputs')\n",
    "coded_gs_results.to_csv('coded_gs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, save off the best results into a final output dataframe\n",
    "# create a df to collect the best models from all grid search tuning efforts\n",
    "# save it off to a csv\n",
    "coded_final_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                            'passes', 'per-word bounds', \n",
    "                                            'perplexity', 'topic diff', \n",
    "                                            'final perplexity', 'final topic diff', \n",
    "                                            'perplexity decreasing', 'coherence', \n",
    "                                            'top_n removed', 'n_above threshold'])\n",
    "\n",
    "for product in top_ten:\n",
    "    output = coded_gs_results[coded_gs_results['product']==product]\n",
    "    coded_final_results = lda_funcs.save_best(output, coded_final_results, \n",
    "                                              save_path='coded_outputs')\n",
    "\n",
    "coded_final_results.to_csv('coded_final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "# load in the final results\n",
    "coded_final_results = pd.read_csv('coded_final_results.csv')\n",
    "coded_final_results.set_index('product', inplace=True)\n",
    "coded_final_results[['coherence', 'num_topics', 'passes', \n",
    "                     'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the coded review (i.e., with \"GOODREVIEW\" and \"BADREVIEW\" inserted following each positive or negative word), the coherence results are somewhat better than the uncoded reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence Coded Inputs Grid Search & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION - GRID SEARCH CAN TAKE MANY HOURS TO RUN\n",
    "# ONLY RUN ON FIRST PASS\n",
    "# create a dataframe to house the results of the model tuning from an initial grid search\n",
    "\n",
    "valence_gs_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                           'passes', 'per-word bounds', \n",
    "                                           'perplexity', 'topic diff', \n",
    "                                           'final perplexity', 'final topic diff', \n",
    "                                           'perplexity decreasing', 'coherence', \n",
    "                                           'top_n removed', 'n_above threshold'])\n",
    "\n",
    "# for each of the top ten products, grid search over a combination of n_passes and n_topics \n",
    "# save the parameter combinations (and saved model) of the model with the highest coherence score\n",
    "for product in top_ten:\n",
    "    output = lda_funcs.tune_lda(df=df, product=product, n_passes=[50, 80], \n",
    "                                n_topics=[6, 8, 10, 12], save_path='valence_outputs', \n",
    "                                input_text='clean_valence', n_below=0, \n",
    "                                top_n=[2,10], n_above=[0.5, 1.0])\n",
    "    valence_gs_results = lda_funcs.save_best(output, valence_gs_results, \n",
    "                                             save_path='valence_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ON FIRST PASS\n",
    "# save off the results with the best model (highest coherence) for each product\n",
    "# examine the results\n",
    "valence_gs_results.to_csv('valence_gs_results.csv')\n",
    "valence_gs_results[['product','coherence', 'num_topics', \n",
    "                    'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>coherence</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>passes</th>\n",
       "      <th>top_n removed</th>\n",
       "      <th>n_above threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B002IEZJMA</td>\n",
       "      <td>0.492564</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006MONQMC</td>\n",
       "      <td>0.502877</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B005ZBZLT4</td>\n",
       "      <td>0.470262</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B003GTR8IO</td>\n",
       "      <td>0.518304</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B005K4Q34S</td>\n",
       "      <td>0.497359</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0013A0QXC</td>\n",
       "      <td>0.485961</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B000NMJWZO</td>\n",
       "      <td>0.490841</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B000KV61FC</td>\n",
       "      <td>0.523329</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B001EO5Q64</td>\n",
       "      <td>0.488493</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B0026RQTGE</td>\n",
       "      <td>0.438051</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B0026RQTGE</td>\n",
       "      <td>0.462235</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B000KV61FC</td>\n",
       "      <td>0.523329</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product  coherence  num_topics  passes  top_n removed  \\\n",
       "0   B002IEZJMA   0.492564          12      50             10   \n",
       "1   B006MONQMC   0.502877           8      50              2   \n",
       "2   B005ZBZLT4   0.470262          12      80              2   \n",
       "3   B003GTR8IO   0.518304          12      80              2   \n",
       "4   B005K4Q34S   0.497359           8      80              2   \n",
       "5   B0013A0QXC   0.485961          10      80              2   \n",
       "6   B000NMJWZO   0.490841           8      50              2   \n",
       "7   B000KV61FC   0.523329           8      80             10   \n",
       "8   B001EO5Q64   0.488493           6      50             10   \n",
       "9   B0026RQTGE   0.438051           6      80              2   \n",
       "10  B0026RQTGE   0.462235           5      80             10   \n",
       "11  B000KV61FC   0.523329           8      80             10   \n",
       "\n",
       "    n_above threshold  \n",
       "0                 0.5  \n",
       "1                 1.0  \n",
       "2                 0.5  \n",
       "3                 1.0  \n",
       "4                 0.5  \n",
       "5                 0.5  \n",
       "6                 1.0  \n",
       "7                 0.5  \n",
       "8                 0.5  \n",
       "9                 0.5  \n",
       "10                0.5  \n",
       "11                0.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD RESULTS\n",
    "valence_gs_results = pd.read_csv('valence_gs_results.csv')\n",
    "valence_gs_results[['product','coherence', 'num_topics', \n",
    "                    'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after reviewing the results of the initial grid search pass, and manually tune the models for each of the products to try to reach a threshold of 0.5 for the final model coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell for the product that needs further tuning\n",
    "output = lda_funcs.tune_lda(df=df, product='B001EO5Q64', n_passes=[50], \n",
    "                            n_topics=[6], save_path='valence_outputs',\n",
    "                            input_text='clean_valence', n_below=0,\n",
    "                           top_n=[10], n_above=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the outputs\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the result is an improvement, run this cell to save it\n",
    "# save off the updated results dataframe\n",
    "valence_gs_results = lda_funcs.save_best(output, valence_gs_results, save_path=\"valence_outputs\")\n",
    "valence_gs_results.to_csv('valence_gs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:02,662 : INFO : loading LdaModel object from ./valence_outputs/B002IEZJMA_12_50_10_0.5\n",
      "2018-10-04 13:51:02,669 : INFO : loading expElogbeta from ./valence_outputs/B002IEZJMA_12_50_10_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:02,674 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:02,680 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:02,682 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:02,683 : INFO : loaded ./valence_outputs/B002IEZJMA_12_50_10_0.5\n",
      "2018-10-04 13:51:02,685 : INFO : loading LdaState object from ./valence_outputs/B002IEZJMA_12_50_10_0.5.state\n",
      "2018-10-04 13:51:02,690 : INFO : loaded ./valence_outputs/B002IEZJMA_12_50_10_0.5.state\n",
      "2018-10-04 13:51:02,703 : INFO : saving LdaState object under ./valence_outputs/final_models/B002IEZJMA_12_50_10_0.5.state, separately None\n",
      "2018-10-04 13:51:02,718 : INFO : saved ./valence_outputs/final_models/B002IEZJMA_12_50_10_0.5.state\n",
      "2018-10-04 13:51:02,730 : INFO : saving LdaModel object under ./valence_outputs/final_models/B002IEZJMA_12_50_10_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:02,733 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:02,735 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:02,736 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:02,738 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B002IEZJMA_12_50_10_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:02,746 : INFO : saved ./valence_outputs/final_models/B002IEZJMA_12_50_10_0.5\n",
      "2018-10-04 13:51:02,789 : INFO : loading LdaModel object from ./valence_outputs/B006MONQMC_8_50_2_1.0\n",
      "2018-10-04 13:51:02,791 : INFO : loading expElogbeta from ./valence_outputs/B006MONQMC_8_50_2_1.0.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:02,795 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:02,799 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:02,802 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:02,805 : INFO : loaded ./valence_outputs/B006MONQMC_8_50_2_1.0\n",
      "2018-10-04 13:51:02,809 : INFO : loading LdaState object from ./valence_outputs/B006MONQMC_8_50_2_1.0.state\n",
      "2018-10-04 13:51:02,813 : INFO : loaded ./valence_outputs/B006MONQMC_8_50_2_1.0.state\n",
      "2018-10-04 13:51:02,820 : INFO : saving LdaState object under ./valence_outputs/final_models/B006MONQMC_8_50_2_1.0.state, separately None\n",
      "2018-10-04 13:51:02,824 : INFO : saved ./valence_outputs/final_models/B006MONQMC_8_50_2_1.0.state\n",
      "2018-10-04 13:51:02,829 : INFO : saving LdaModel object under ./valence_outputs/final_models/B006MONQMC_8_50_2_1.0, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:02,833 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:02,836 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:02,839 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:02,842 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B006MONQMC_8_50_2_1.0.expElogbeta.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best results for product B002IEZJMA:\n",
      "level_0                                                                  0\n",
      "Unnamed: 0                                                               0\n",
      "Unnamed: 0.1                                                             0\n",
      "product                                                         B002IEZJMA\n",
      "num_topics                                                              12\n",
      "chunk                                                              162.333\n",
      "passes                                                                  50\n",
      "per-word bounds          {0: -8.081, 1: -5.316, 2: -4.657, 3: -4.471, 4...\n",
      "perplexity               {0: 270.7, 1: 39.8, 2: 25.2, 3: 22.2, 4: 21.1,...\n",
      "topic diff               {0: 0.792344, 1: 0.500671, 2: 0.397751, 3: 0.3...\n",
      "final perplexity                                                      17.5\n",
      "final topic diff                                                  0.077463\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.492564\n",
      "top_n removed                                                           10\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('odd', 0.012630275), ('pass', 0.011671715), ...\n",
      "topic 1                  [('unless', 0.020114824), ('restaurant', 0.011...\n",
      "topic 10                 [('market', 0.015859151), ('name', 0.012152788...\n",
      "topic 11                 [('GOODREVIEW', 0.08732022), ('BADREVIEW', 0.0...\n",
      "topic 2                  [('ounce', 0.03973756), ('cent', 0.019578645),...\n",
      "topic 3                  [('mocha', 0.021995176), ('mild', 0.016587013)...\n",
      "topic 4                  [('GOODREVIEW', 0.10529692), ('BADREVIEW', 0.0...\n",
      "topic 5                  [('weird', 0.3243718), ('metal', 0.007219691),...\n",
      "topic 6                  [('GOODREVIEW', 0.15360352), ('BADREVIEW', 0.0...\n",
      "topic 7                  [('away', 0.007628411), ('eat', 0.007537121), ...\n",
      "topic 8                  [('expresso', 0.027527636), ('pot', 0.01293542...\n",
      "topic 9                  [('nasty', 0.013459884), ('camp', 0.009327094)...\n",
      "Name: 0, dtype: object\n",
      "Final model saved for product B002IEZJMA with 12 topics over 50 passes, removing top 10 tokens and token review threshold 0.5.\n",
      "best results for product B006MONQMC:\n",
      "level_0                                                                  1\n",
      "Unnamed: 0                                                               1\n",
      "Unnamed: 0.1                                                             1\n",
      "product                                                         B006MONQMC\n",
      "num_topics                                                               8\n",
      "chunk                                                              163.667\n",
      "passes                                                                  50\n",
      "per-word bounds          {0: -7.065, 1: -5.81, 2: -5.3, 3: -5.073, 4: -...\n",
      "perplexity               {0: 133.9, 1: 56.1, 2: 39.4, 3: 33.7, 4: 30.8,...\n",
      "topic diff               {0: 0.764678, 1: 0.504039, 2: 0.372283, 3: 0.3...\n",
      "final perplexity                                                      23.4\n",
      "final topic diff                                                  0.106498\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.502877\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                        1\n",
      "index                                                                    0\n",
      "topic 0                  [('doctor', 0.0056774174), ('seriously', 0.005...\n",
      "topic 1                  [('GOODREVIEW', 0.066889234), ('BADREVIEW', 0....\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('b', 0.039773148), ('GOODREVIEW', 0.03587005...\n",
      "topic 3                  [('sucralose', 0.016014539), ('pull', 0.008660...\n",
      "topic 4                  [('liter', 0.10938923), ('tonic', 0.0043434547...\n",
      "topic 5                  [('GOODREVIEW', 0.11060637), ('drink', 0.03639...\n",
      "topic 6                  [('synthetic', 0.1115367), ('pill', 0.01468350...\n",
      "topic 7                  [('nutritious', 0.009909276), ('seal', 0.00901...\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:02,849 : INFO : saved ./valence_outputs/final_models/B006MONQMC_8_50_2_1.0\n",
      "2018-10-04 13:51:02,892 : INFO : loading LdaModel object from ./valence_outputs/B005ZBZLT4_12_80_2_0.5\n",
      "2018-10-04 13:51:02,896 : INFO : loading expElogbeta from ./valence_outputs/B005ZBZLT4_12_80_2_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:02,901 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:02,904 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:02,906 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:02,908 : INFO : loaded ./valence_outputs/B005ZBZLT4_12_80_2_0.5\n",
      "2018-10-04 13:51:02,909 : INFO : loading LdaState object from ./valence_outputs/B005ZBZLT4_12_80_2_0.5.state\n",
      "2018-10-04 13:51:02,915 : INFO : loaded ./valence_outputs/B005ZBZLT4_12_80_2_0.5.state\n",
      "2018-10-04 13:51:02,923 : INFO : saving LdaState object under ./valence_outputs/final_models/B005ZBZLT4_12_80_2_0.5.state, separately None\n",
      "2018-10-04 13:51:02,928 : INFO : saved ./valence_outputs/final_models/B005ZBZLT4_12_80_2_0.5.state\n",
      "2018-10-04 13:51:02,936 : INFO : saving LdaModel object under ./valence_outputs/final_models/B005ZBZLT4_12_80_2_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:02,937 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:02,939 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:02,941 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:02,947 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B005ZBZLT4_12_80_2_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:02,954 : INFO : saved ./valence_outputs/final_models/B005ZBZLT4_12_80_2_0.5\n",
      "2018-10-04 13:51:03,004 : INFO : loading LdaModel object from ./valence_outputs/B003GTR8IO_12_80_2_1.0\n",
      "2018-10-04 13:51:03,010 : INFO : loading expElogbeta from ./valence_outputs/B003GTR8IO_12_80_2_1.0.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,022 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,026 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,029 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,034 : INFO : loaded ./valence_outputs/B003GTR8IO_12_80_2_1.0\n",
      "2018-10-04 13:51:03,036 : INFO : loading LdaState object from ./valence_outputs/B003GTR8IO_12_80_2_1.0.state\n",
      "2018-10-04 13:51:03,043 : INFO : loaded ./valence_outputs/B003GTR8IO_12_80_2_1.0.state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved for product B006MONQMC with 8 topics over 50 passes, removing top 2 tokens and token review threshold 1.0.\n",
      "best results for product B005ZBZLT4:\n",
      "level_0                                                                  2\n",
      "Unnamed: 0                                                               2\n",
      "Unnamed: 0.1                                                             2\n",
      "product                                                         B005ZBZLT4\n",
      "num_topics                                                              12\n",
      "chunk                                                              168.667\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -6.924, 1: -5.579, 2: -5.367, 3: -5.186, 4...\n",
      "perplexity               {0: 121.5, 1: 47.8, 2: 41.3, 3: 36.4, 4: 32.3,...\n",
      "topic diff               {0: 0.775349, 1: 0.502837, 2: 0.395454, 3: 0.3...\n",
      "final perplexity                                                      23.9\n",
      "final topic diff                                                  0.059602\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.470262\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('delivery', 0.030316606), ('continue', 0.019...\n",
      "topic 1                  [('lid', 0.015668958), ('life', 0.013325884), ...\n",
      "topic 10                 [('grocery', 0.026318459), ('watery', 0.012859...\n",
      "topic 11                 [('choose', 0.02112708), ('enjoy', 0.019792369...\n",
      "topic 2                  [('GOODREVIEW', 0.080515146), ('VGOODREVIEW', ...\n",
      "topic 3                  [('harsh', 0.13773301), ('ten', 0.12973085), (...\n",
      "topic 4                  [('GOODREVIEW', 0.1526125), ('good', 0.0653139...\n",
      "topic 5                  [('pick', 0.018806592), ('aromatic', 0.0113852...\n",
      "topic 6                  [('BADREVIEW', 0.10278634), ('GOODREVIEW', 0.0...\n",
      "topic 7                  [('onecup', 0.019038761), ('highly', 0.0184671...\n",
      "topic 8                  [('run', 0.02701575), ('thanks', 0.016910937),...\n",
      "topic 9                  [('interesting', 0.08320758), ('settle', 0.082...\n",
      "Name: 0, dtype: object\n",
      "Final model saved for product B005ZBZLT4 with 12 topics over 80 passes, removing top 2 tokens and token review threshold 0.5.\n",
      "best results for product B003GTR8IO:\n",
      "level_0                                                                  3\n",
      "Unnamed: 0                                                               3\n",
      "Unnamed: 0.1                                                             3\n",
      "product                                                         B003GTR8IO\n",
      "num_topics                                                              12\n",
      "chunk                                                              176.667\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -6.498, 1: -5.523, 2: -5.424, 3: -5.36, 4:...\n",
      "perplexity               {0: 90.4, 1: 46.0, 2: 42.9, 3: 41.1, 4: 38.7, ...\n",
      "topic diff               {0: 0.707784, 1: 0.418485, 2: 0.288527, 3: 0.2...\n",
      "final perplexity                                                      29.1\n",
      "final topic diff                                                  0.052458\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.518304\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                        1\n",
      "index                                                                    0\n",
      "topic 0                  [('clear', 0.15143195), ('traditional', 0.0095...\n",
      "topic 1                  [('trade', 0.020039191), ('spice', 0.014129072...\n",
      "topic 10                 [('BADREVIEW', 0.064661734), ('try', 0.0544007...\n",
      "topic 11                 [('awesome', 0.0117281815), ('customer', 0.008...\n",
      "topic 2                  [('cold', 0.016594777), ('unpleasant', 0.00981...\n",
      "topic 3                  [('GOODREVIEW', 0.08064756), ('BADREVIEW', 0.0...\n",
      "topic 4                  [('cooky', 0.012165307), ('con', 0.010308159),...\n",
      "topic 5                  [('milk', 0.013543844), ('espresso', 0.0107134...\n",
      "topic 6                  [('iced', 0.015152243), ('happen', 0.013692753...\n",
      "topic 7                  [('ingredient', 0.045877073), ('root', 0.04045...\n",
      "topic 8                  [('method', 0.010499871), ('ton', 0.0077238204...\n",
      "topic 9                  [('press', 0.02154127), ('drip', 0.01999276), ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:03,060 : INFO : saving LdaState object under ./valence_outputs/final_models/B003GTR8IO_12_80_2_1.0.state, separately None\n",
      "2018-10-04 13:51:03,068 : INFO : saved ./valence_outputs/final_models/B003GTR8IO_12_80_2_1.0.state\n",
      "2018-10-04 13:51:03,074 : INFO : saving LdaModel object under ./valence_outputs/final_models/B003GTR8IO_12_80_2_1.0, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,078 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,080 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,083 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,085 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B003GTR8IO_12_80_2_1.0.expElogbeta.npy\n",
      "2018-10-04 13:51:03,094 : INFO : saved ./valence_outputs/final_models/B003GTR8IO_12_80_2_1.0\n",
      "2018-10-04 13:51:03,142 : INFO : loading LdaModel object from ./valence_outputs/B005K4Q34S_8_80_2_0.5\n",
      "2018-10-04 13:51:03,150 : INFO : loading expElogbeta from ./valence_outputs/B005K4Q34S_8_80_2_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,152 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,157 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,158 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,160 : INFO : loaded ./valence_outputs/B005K4Q34S_8_80_2_0.5\n",
      "2018-10-04 13:51:03,164 : INFO : loading LdaState object from ./valence_outputs/B005K4Q34S_8_80_2_0.5.state\n",
      "2018-10-04 13:51:03,170 : INFO : loaded ./valence_outputs/B005K4Q34S_8_80_2_0.5.state\n",
      "2018-10-04 13:51:03,175 : INFO : saving LdaState object under ./valence_outputs/final_models/B005K4Q34S_8_80_2_0.5.state, separately None\n",
      "2018-10-04 13:51:03,180 : INFO : saved ./valence_outputs/final_models/B005K4Q34S_8_80_2_0.5.state\n",
      "2018-10-04 13:51:03,184 : INFO : saving LdaModel object under ./valence_outputs/final_models/B005K4Q34S_8_80_2_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,186 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,188 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,191 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,196 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B005K4Q34S_8_80_2_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:03,203 : INFO : saved ./valence_outputs/final_models/B005K4Q34S_8_80_2_0.5\n",
      "2018-10-04 13:51:03,264 : INFO : loading LdaModel object from ./valence_outputs/B0013A0QXC_10_80_2_0.5\n",
      "2018-10-04 13:51:03,267 : INFO : loading expElogbeta from ./valence_outputs/B0013A0QXC_10_80_2_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,273 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,276 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,280 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,285 : INFO : loaded ./valence_outputs/B0013A0QXC_10_80_2_0.5\n",
      "2018-10-04 13:51:03,289 : INFO : loading LdaState object from ./valence_outputs/B0013A0QXC_10_80_2_0.5.state\n",
      "2018-10-04 13:51:03,293 : INFO : loaded ./valence_outputs/B0013A0QXC_10_80_2_0.5.state\n",
      "2018-10-04 13:51:03,298 : INFO : saving LdaState object under ./valence_outputs/final_models/B0013A0QXC_10_80_2_0.5.state, separately None\n",
      "2018-10-04 13:51:03,308 : INFO : saved ./valence_outputs/final_models/B0013A0QXC_10_80_2_0.5.state\n",
      "2018-10-04 13:51:03,312 : INFO : saving LdaModel object under ./valence_outputs/final_models/B0013A0QXC_10_80_2_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,317 : INFO : not storing attribute state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved for product B003GTR8IO with 12 topics over 80 passes, removing top 2 tokens and token review threshold 1.0.\n",
      "best results for product B005K4Q34S:\n",
      "level_0                                                                  4\n",
      "Unnamed: 0                                                               4\n",
      "Unnamed: 0.1                                                             4\n",
      "product                                                         B005K4Q34S\n",
      "num_topics                                                               8\n",
      "chunk                                                              180.333\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -8.385, 1: -5.311, 2: -4.623, 3: -4.254, 4...\n",
      "perplexity               {0: 334.4, 1: 39.7, 2: 24.6, 3: 19.1, 4: 17.0,...\n",
      "topic diff               {0: 0.661038, 1: 0.533929, 2: 0.475783, 3: 0.4...\n",
      "final perplexity                                                      13.1\n",
      "final topic diff                                                  0.065785\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.497359\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('station', 0.0684471), ('gas', 0.06550074), ...\n",
      "topic 1                  [('GOODREVIEW', 0.14461584), ('flavor', 0.0954...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('change', 0.2513749), ('catch', 0.24622004),...\n",
      "topic 3                  [('surprise', 0.022388762), ('fat', 0.01772514...\n",
      "topic 4                  [('GOODREVIEW', 0.088677645), ('BADREVIEW', 0....\n",
      "topic 5                  [('ingredient', 0.030833833), ('oil', 0.020377...\n",
      "topic 6                  [('splenda', 0.015933089), ('local', 0.0151196...\n",
      "topic 7                  [('shop', 0.024452636), ('several', 0.01826658...\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 0, dtype: object\n",
      "Final model saved for product B005K4Q34S with 8 topics over 80 passes, removing top 2 tokens and token review threshold 0.5.\n",
      "best results for product B0013A0QXC:\n",
      "level_0                                                                  5\n",
      "Unnamed: 0                                                               5\n",
      "Unnamed: 0.1                                                             5\n",
      "product                                                         B0013A0QXC\n",
      "num_topics                                                              10\n",
      "chunk                                                              180.667\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -8.538, 1: -5.488, 2: -4.989, 3: -4.587, 4...\n",
      "perplexity               {0: 371.7, 1: 44.9, 2: 31.8, 3: 24.0, 4: 22.2,...\n",
      "topic diff               {0: 0.726086, 1: 0.512752, 2: 0.461047, 3: 0.4...\n",
      "final perplexity                                                      17.7\n",
      "final topic diff                                                  0.051095\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.485961\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('brewer', 0.02188663), ('batch', 0.016965207...\n",
      "topic 1                  [('GOODREVIEW', 0.072445355), ('VGOODREVIEW', ...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('wonderful', 0.095870525), ('foam', 0.090464...\n",
      "topic 3                  [('etc', 0.012075101), ('sale', 0.011263032), ...\n",
      "topic 4                  [('bag', 0.03668458), ('price', 0.02783308), (...\n",
      "topic 5                  [('excellent', 0.036114205), ('extra', 0.02064...\n",
      "topic 6                  [('VGOODREVIEW', 0.12041943), ('get', 0.082077...\n",
      "topic 7                  [('GOODREVIEW', 0.090591095), ('BADREVIEW', 0....\n",
      "topic 8                  [('VGOODREVIEW', 0.10949906), ('BADREVIEW', 0....\n",
      "topic 9                  [('difference', 0.01605744), ('low', 0.0144443...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:03,321 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,327 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,329 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B0013A0QXC_10_80_2_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:03,336 : INFO : saved ./valence_outputs/final_models/B0013A0QXC_10_80_2_0.5\n",
      "2018-10-04 13:51:03,401 : INFO : loading LdaModel object from ./valence_outputs/B000NMJWZO_8_50_2_1.0\n",
      "2018-10-04 13:51:03,411 : INFO : loading expElogbeta from ./valence_outputs/B000NMJWZO_8_50_2_1.0.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,425 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,429 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,431 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,433 : INFO : loaded ./valence_outputs/B000NMJWZO_8_50_2_1.0\n",
      "2018-10-04 13:51:03,436 : INFO : loading LdaState object from ./valence_outputs/B000NMJWZO_8_50_2_1.0.state\n",
      "2018-10-04 13:51:03,444 : INFO : loaded ./valence_outputs/B000NMJWZO_8_50_2_1.0.state\n",
      "2018-10-04 13:51:03,451 : INFO : saving LdaState object under ./valence_outputs/final_models/B000NMJWZO_8_50_2_1.0.state, separately None\n",
      "2018-10-04 13:51:03,455 : INFO : saved ./valence_outputs/final_models/B000NMJWZO_8_50_2_1.0.state\n",
      "2018-10-04 13:51:03,460 : INFO : saving LdaModel object under ./valence_outputs/final_models/B000NMJWZO_8_50_2_1.0, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,462 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,466 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,469 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,472 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B000NMJWZO_8_50_2_1.0.expElogbeta.npy\n",
      "2018-10-04 13:51:03,477 : INFO : saved ./valence_outputs/final_models/B000NMJWZO_8_50_2_1.0\n",
      "2018-10-04 13:51:03,532 : INFO : loading LdaModel object from ./valence_outputs/B000KV61FC_8_80_10_0.5\n",
      "2018-10-04 13:51:03,537 : INFO : loading expElogbeta from ./valence_outputs/B000KV61FC_8_80_10_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,543 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,545 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,548 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,551 : INFO : loaded ./valence_outputs/B000KV61FC_8_80_10_0.5\n",
      "2018-10-04 13:51:03,553 : INFO : loading LdaState object from ./valence_outputs/B000KV61FC_8_80_10_0.5.state\n",
      "2018-10-04 13:51:03,559 : INFO : loaded ./valence_outputs/B000KV61FC_8_80_10_0.5.state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved for product B0013A0QXC with 10 topics over 80 passes, removing top 2 tokens and token review threshold 0.5.\n",
      "best results for product B000NMJWZO:\n",
      "level_0                                                                  6\n",
      "Unnamed: 0                                                               6\n",
      "Unnamed: 0.1                                                             6\n",
      "product                                                         B000NMJWZO\n",
      "num_topics                                                               8\n",
      "chunk                                                              180.667\n",
      "passes                                                                  50\n",
      "per-word bounds          {0: -6.914, 1: -5.486, 2: -5.252, 3: -5.084, 4...\n",
      "perplexity               {0: 120.6, 1: 44.8, 2: 38.1, 3: 33.9, 4: 32.2,...\n",
      "topic diff               {0: 1.13664, 1: 0.730187, 2: 0.575428, 3: 0.50...\n",
      "final perplexity                                                      23.3\n",
      "final topic diff                                                   0.12471\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.490841\n",
      "top_n removed                                                            2\n",
      "n_above threshold                                                        1\n",
      "index                                                                    0\n",
      "topic 0                  [('gum', 0.061079595), ('xanthan', 0.060783096...\n",
      "topic 1                  [('idea', 0.1486574), ('donut', 0.011029639), ...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('VGOODREVIEW', 0.09282417), ('GOODREVIEW', 0...\n",
      "topic 3                  [('overpower', 0.13027628), ('baker', 0.130264...\n",
      "topic 4                  [('overall', 0.12917915), ('complaint', 0.1282...\n",
      "topic 5                  [('BADREVIEW', 0.06448552), ('GOODREVIEW', 0.0...\n",
      "topic 6                  [('pie', 0.022290573), ('brown', 0.019570272),...\n",
      "topic 7                  [('VGOODREVIEW', 0.07877243), ('GOODREVIEW', 0...\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 0, dtype: object\n",
      "Final model saved for product B000NMJWZO with 8 topics over 50 passes, removing top 2 tokens and token review threshold 1.0.\n",
      "best results for product B000KV61FC:\n",
      "level_0                                                                  7\n",
      "Unnamed: 0                                                               7\n",
      "Unnamed: 0.1                                                             7\n",
      "product                                                         B000KV61FC\n",
      "num_topics                                                               8\n",
      "chunk                                                              185.333\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -6.339, 1: -4.639, 2: -4.221, 3: -4.164, 4...\n",
      "perplexity               {0: 81.0, 1: 24.9, 2: 18.7, 3: 17.9, 4: 17.6, ...\n",
      "topic diff               {0: 0.720535, 1: 0.579795, 2: 0.457481, 3: 0.3...\n",
      "final perplexity                                                      16.1\n",
      "final topic diff                                                  0.048811\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.523329\n",
      "top_n removed                                                           10\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('VGOODREVIEW', 0.07608419), ('work', 0.04981...\n",
      "topic 1                  [('rough', 0.01753488), ('etc', 0.0154024875),...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('strategy', 0.0061185113), ('fragile', 0.005...\n",
      "topic 3                  [('GOODREVIEW', 0.07722169), ('BADREVIEW', 0.0...\n",
      "topic 4                  [('floor', 0.012176747), ('carpet', 0.01043145...\n",
      "topic 5                  [('buddy', 0.0127637535), ('favorite', 0.01047...\n",
      "topic 6                  [('hope', 0.012151097), ('bottom', 0.010960985...\n",
      "topic 7                  [('version', 0.019015951), ('unfortunately', 0...\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:03,568 : INFO : saving LdaState object under ./valence_outputs/final_models/B000KV61FC_8_80_10_0.5.state, separately None\n",
      "2018-10-04 13:51:03,572 : INFO : saved ./valence_outputs/final_models/B000KV61FC_8_80_10_0.5.state\n",
      "2018-10-04 13:51:03,578 : INFO : saving LdaModel object under ./valence_outputs/final_models/B000KV61FC_8_80_10_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,580 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,584 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,587 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,590 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B000KV61FC_8_80_10_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:03,596 : INFO : saved ./valence_outputs/final_models/B000KV61FC_8_80_10_0.5\n",
      "2018-10-04 13:51:03,648 : INFO : loading LdaModel object from ./valence_outputs/B001EO5Q64_6_50_10_0.5\n",
      "2018-10-04 13:51:03,655 : INFO : loading expElogbeta from ./valence_outputs/B001EO5Q64_6_50_10_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,660 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,662 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,666 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,670 : INFO : loaded ./valence_outputs/B001EO5Q64_6_50_10_0.5\n",
      "2018-10-04 13:51:03,674 : INFO : loading LdaState object from ./valence_outputs/B001EO5Q64_6_50_10_0.5.state\n",
      "2018-10-04 13:51:03,681 : INFO : loaded ./valence_outputs/B001EO5Q64_6_50_10_0.5.state\n",
      "2018-10-04 13:51:03,690 : INFO : saving LdaState object under ./valence_outputs/final_models/B001EO5Q64_6_50_10_0.5.state, separately None\n",
      "2018-10-04 13:51:03,694 : INFO : saved ./valence_outputs/final_models/B001EO5Q64_6_50_10_0.5.state\n",
      "2018-10-04 13:51:03,699 : INFO : saving LdaModel object under ./valence_outputs/final_models/B001EO5Q64_6_50_10_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,703 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,704 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,706 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,711 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B001EO5Q64_6_50_10_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:03,718 : INFO : saved ./valence_outputs/final_models/B001EO5Q64_6_50_10_0.5\n",
      "2018-10-04 13:51:03,775 : INFO : loading LdaModel object from ./valence_outputs/B0026RQTGE_5_80_10_0.5\n",
      "2018-10-04 13:51:03,776 : INFO : loading expElogbeta from ./valence_outputs/B0026RQTGE_5_80_10_0.5.expElogbeta.npy with mmap=None\n",
      "2018-10-04 13:51:03,782 : INFO : setting ignored attribute state to None\n",
      "2018-10-04 13:51:03,785 : INFO : setting ignored attribute id2word to None\n",
      "2018-10-04 13:51:03,786 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-04 13:51:03,789 : INFO : loaded ./valence_outputs/B0026RQTGE_5_80_10_0.5\n",
      "2018-10-04 13:51:03,792 : INFO : loading LdaState object from ./valence_outputs/B0026RQTGE_5_80_10_0.5.state\n",
      "2018-10-04 13:51:03,796 : INFO : loaded ./valence_outputs/B0026RQTGE_5_80_10_0.5.state\n",
      "2018-10-04 13:51:03,803 : INFO : saving LdaState object under ./valence_outputs/final_models/B0026RQTGE_5_80_10_0.5.state, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved for product B000KV61FC with 8 topics over 80 passes, removing top 10 tokens and token review threshold 0.5.\n",
      "best results for product B001EO5Q64:\n",
      "level_0                                                                  8\n",
      "Unnamed: 0                                                               8\n",
      "Unnamed: 0.1                                                             8\n",
      "product                                                         B001EO5Q64\n",
      "num_topics                                                               6\n",
      "chunk                                                                  189\n",
      "passes                                                                  50\n",
      "per-word bounds          {0: -7.686, 1: -7.134, 2: -7.035, 3: -6.969, 4...\n",
      "perplexity               {0: 205.9, 1: 140.5, 2: 131.1, 3: 125.3, 4: 12...\n",
      "topic diff               {0: 1.266589, 1: 0.476273, 2: 0.333173, 3: 0.2...\n",
      "final perplexity                                                     109.6\n",
      "final topic diff                                                  0.039286\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.488493\n",
      "top_n removed                                                           10\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('GOODREVIEW', 0.07665644), ('BADREVIEW', 0.0...\n",
      "topic 1                  [('minute', 0.006171797), ('delivery', 0.00507...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('return', 0.011523371), ('pancake', 0.010369...\n",
      "topic 3                  [('GOODREVIEW', 0.095735304), ('VGOODREVIEW', ...\n",
      "topic 4                  [('VGOODREVIEW', 0.065934666), ('butter', 0.02...\n",
      "topic 5                  [('BADREVIEW', 0.039618805), ('fat', 0.0237403...\n",
      "topic 6                                                                NaN\n",
      "topic 7                                                                NaN\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 0, dtype: object\n",
      "Final model saved for product B001EO5Q64 with 6 topics over 50 passes, removing top 10 tokens and token review threshold 0.5.\n",
      "best results for product B0026RQTGE:\n",
      "level_0                                                                 10\n",
      "Unnamed: 0                                                              10\n",
      "Unnamed: 0.1                                                           NaN\n",
      "product                                                         B0026RQTGE\n",
      "num_topics                                                               5\n",
      "chunk                                                                  210\n",
      "passes                                                                  80\n",
      "per-word bounds          {0: -7.444, 1: -6.93, 2: -6.848, 3: -6.804, 4:...\n",
      "perplexity               {0: 174.1, 1: 122.0, 2: 115.2, 3: 111.7, 4: 10...\n",
      "topic diff               {0: 1.049921, 1: 0.419105, 2: 0.302282, 3: 0.2...\n",
      "final perplexity                                                      97.6\n",
      "final topic diff                                                  0.048299\n",
      "perplexity decreasing                                                 True\n",
      "coherence                                                         0.462235\n",
      "top_n removed                                                           10\n",
      "n_above threshold                                                      0.5\n",
      "index                                                                    0\n",
      "topic 0                  [('BADREVIEW', 0.07638079), ('GOODREVIEW', 0.0...\n",
      "topic 1                  [('crate', 0.008953248), ('u', 0.008157616), (...\n",
      "topic 10                                                               NaN\n",
      "topic 11                                                               NaN\n",
      "topic 2                  [('VGOODREVIEW', 0.097440876), ('GOODREVIEW', ...\n",
      "topic 3                  [('GOODREVIEW', 0.08886161), ('VGOODREVIEW', 0...\n",
      "topic 4                  [('pet', 0.009041211), ('top', 0.0067826845), ...\n",
      "topic 5                                                                NaN\n",
      "topic 6                                                                NaN\n",
      "topic 7                                                                NaN\n",
      "topic 8                                                                NaN\n",
      "topic 9                                                                NaN\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:51:03,808 : INFO : saved ./valence_outputs/final_models/B0026RQTGE_5_80_10_0.5.state\n",
      "2018-10-04 13:51:03,822 : INFO : saving LdaModel object under ./valence_outputs/final_models/B0026RQTGE_5_80_10_0.5, separately ['expElogbeta', 'sstats']\n",
      "2018-10-04 13:51:03,825 : INFO : not storing attribute state\n",
      "2018-10-04 13:51:03,827 : INFO : not storing attribute id2word\n",
      "2018-10-04 13:51:03,832 : INFO : not storing attribute dispatcher\n",
      "2018-10-04 13:51:03,835 : INFO : storing np array 'expElogbeta' to ./valence_outputs/final_models/B0026RQTGE_5_80_10_0.5.expElogbeta.npy\n",
      "2018-10-04 13:51:03,840 : INFO : saved ./valence_outputs/final_models/B0026RQTGE_5_80_10_0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved for product B0026RQTGE with 5 topics over 80 passes, removing top 10 tokens and token review threshold 0.5.\n"
     ]
    }
   ],
   "source": [
    "# finally, save off the best results into a final output dataframe\n",
    "# create a df to collect the best models from all grid search tuning efforts\n",
    "# save it off to a csv\n",
    "valence_final_results = pd.DataFrame(columns=['product', 'num_topics', 'chunk', \n",
    "                                              'passes', 'per-word bounds', \n",
    "                                              'perplexity', 'topic diff',\n",
    "                                              'final perplexity', 'final topic diff', \n",
    "                                              'perplexity decreasing', 'coherence', \n",
    "                                              'top_n removed', 'n_above threshold'])\n",
    "\n",
    "for product in top_ten:\n",
    "    output = valence_gs_results[valence_gs_results['product']==product]\n",
    "    valence_final_results = lda_funcs.save_best(output, valence_final_results, \n",
    "                                                save_path='valence_outputs')\n",
    "\n",
    "valence_final_results.to_csv('valence_final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_final_results.loc[0, 'top_n removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS\n",
    "# load in the final results\n",
    "valence_final_results = pd.read_csv('valence_final_results.csv')\n",
    "valence_final_results.set_index('product', inplace=True)\n",
    "valence_final_results[['coherence', 'num_topics', 'passes', 'top_n removed', 'n_above threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
